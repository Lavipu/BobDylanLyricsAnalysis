---
title: "Bob Dylan Project - Exploratory Analysis"
output:
  pdf_document: default
  html_notebook: default
always_allow_html: true

---
```{r Packages }
library(dplyr)
library(tidytext)
library(tidyr)
library(tidyverse)
library(knitr)
library(magrittr)
library(gridExtra)
library(tm)
library(formattable)
library(widyr)
library(textdata)
library(viridis)
library(ggrepel)
library(circlize) 
library(memery)
library(magick)
library(yarrr) 
library(radarchart) 
library(igraph) 
library(ggraph)
library(wordcloud2)
library (ggplot2)
library(kableExtra)

```


```{r}
library(dplyr)
setwd("C:/Users/lavin/Desktop/Bob Dylan Project/BobDylan")
#read dataset
bob <- read.csv("BobDylanDataset.csv", header = TRUE, sep= ";", stringsAsFactors = FALSE)
## DATA CLEANING
# function to expand contractions in an English-language source
fix.contractions <- function(doc) {
  doc <- gsub("won't", "will not", doc)
  doc <- gsub("can't", "can not", doc)
  doc <- gsub("n't", " not", doc)
  doc <- gsub("'ll", " will", doc)
  doc <- gsub("'re", " are", doc)
  doc <- gsub("'ve", " have", doc)
  doc <- gsub("'m", " am", doc)
  doc <- gsub("'d", " would", doc)
  # 's could be 'is' or could be possessive: it has no expansion
  doc <- gsub("'s", "", doc)
  return(doc)
}
# fix (expand) contractions
bob$lyric <- sapply(bob$lyric, fix.contractions)

# function to remove special characters, if any
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
# remove special characters
bob$lyric <- sapply(bob$lyric, removeSpecialChars)
# convert everything to lower case
bob$lyric <- sapply(bob$lyric, tolower)

#create buckets and group the years into decades
bob <- bob %>%
  mutate(decade = 
           ifelse(bob$year %in% 1962:1969, "1960s", 
                  ifelse(bob$year %in% 1970:1979, "1970s", 
                         ifelse(bob$year %in% 1980:1989, "1980s", 
                                ifelse(bob$year %in% 1990:1999, "1990s", 
                                       ifelse(bob$year %in% 2000:2009, "2000s",
                                              ifelse(bob$year %in% 2010:2017, "2010s",
                                                     "NA")))))))
#REMOVE INSTRUMENTAL SONGS 
#bob$lyric=="instrumental"
bob <- bob[!(bob$lyric=="instrumental"),]
# 8 songs were instrumental, now the dataset contains 440 "lyrical" songs 

my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", 
               "#D55E00", "#009999", "#006600", "#000066", "#66000",
               "#660033", "#006666")
```


```{r Released Songs per Decade}
library(ggplot2)
library(viridis)
#Released Songs per decade
bob %>%
  filter(decade != "NA") %>%
  group_by(decade) %>%
  summarise(number_of_songs = n()) %>%
  ggplot() + 
  geom_bar(aes(x = decade, y = number_of_songs), stat="identity", fill=viridis(6))  +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank(),
        panel.grid.minor = element_blank()) +
  ggtitle("Released Songs") +
  labs(x = NULL, y = "Song Count")
```
```{r Filtering Words}
library(tidytext)
undesirable_words <- c("huh", "lyrics",  "bridge", "fe0f", "yeah", "baby", 
                       "alright", "wanna", "gonna",
                       "whoa", "gotta", "make", "pum",
                       "ooh", "uurh", "pheromone", "poompoom",  
                       "matic", " ai ", " ca ", " la ", "hey", " na ", 
                       " da ", " uh ", " tin ", "  ll", "ooh", "uurh", 
                       "repeats", "la", "da", "uh", "ah")

# Unnest and remove stop words
bob_words_filtered <- bob %>%
  unnest_tokens(word, lyric) %>%
  anti_join(stop_words) %>%
  distinct() %>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3)
```

```{r Top 10 songs with highest word count}
library(formattable)
library(kableExtra)
# TOP 10 SONGS WITH HIGHEST WORD COUNT
full_word_count <- bob %>%
  unnest_tokens(word, lyric) %>%
  group_by(track_title, album) %>%
  summarise(num_words = n()) %>%
  arrange(desc(num_words)) 
  
full_word_count[1:10,] %>%
  ungroup(num_words, track_title) %>%
  mutate(num_words = color_bar("lightblue")(num_words)) %>%
  mutate(song = color_tile("lightpink","lightpink")(track_title)) %>%
  kable("html", escape = FALSE, align = "c", caption = "Songs With Highest Word Count") %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "bordered"), full_width = FALSE)
```
```{r Word Count Distribution}
# WORD COUNT DISTRIBUTION
full_word_count %>%
  ggplot() +
  geom_histogram(aes(x = num_words, fill = bob$decade), bins = nrow(bob)) +
  ylab("Song Count") + 
  xlab("Word Count per Song") +
  ggtitle("Word Count Distribution") +
  theme(plot.title = element_text(hjust = 0.5),legend.title = element_blank(), panel.grid.minor.y = element_blank())
```
```{r Most Frequently Used Words in Bob Dylan Lyrics}
bob_words_filtered %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
  geom_col(aes(word, n), fill = viridis(11, alpha = 0.8)) +
  theme(legend.position = "none", 
        plot.title = element_text(hjust = 0.5),
        panel.grid.major = element_blank()) +
  xlab("") + 
  ylab("Song Count") +
  ggtitle("Most Frequently Used Words in Bob Dylan Lyrics") +
  coord_flip()

```
```{r}
# WORD CLOUD
library(wordcloud2)
bob_words_counts <- bob_words_filtered %>%
  count(word, sort = TRUE) 

wordcloud2(bob_words_counts[1:300, ], size = .5)
```


```{r}
library(tidyr)
theme_lyrics <- function() 
{
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_blank(), 
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
}
#TTIMELESS WORDS: words over decades 

timeless_words <- bob_words_filtered %>% 
  filter(decade != 'NA') %>%
  group_by(decade) %>%
  count(word, decade, sort = TRUE) %>%
  slice(seq_len(8)) %>%
  ungroup() %>%
  arrange(decade,n) %>%
  mutate(row = row_number()) 

timeless_words %>%
  ggplot(aes(row, n, fill = decade)) +
  geom_col(show.legend = NULL) +
  labs(x = NULL, y = "Song Count") +
  ggtitle("Timeless Words") + 
  theme_lyrics() +  
  facet_wrap(~decade, scales = "free", ncol = 3) +
  scale_x_continuous( 
    breaks = timeless_words$row,
    labels = timeless_words$word) +
  coord_flip()
```
```{r}
# WORD LENGTH 
bob_word_lengths <- bob %>%
  unnest_tokens(word, lyric) %>%
  group_by(track_title,decade) %>%
  distinct() %>%
  filter(!word %in% undesirable_words) %>%
  mutate(word_length = nchar(word)) 

bob_word_lengths %>%
  count(word_length, sort = TRUE) %>%
  ggplot(aes(word_length), binwidth = 0.5) + 
  geom_histogram(aes(fill = ..count..), breaks = seq(1,50, by = 1), show.legend = FALSE, na.rm = TRUE) + 
  xlab("Word Length") + 
  ylab("Word Count") +
  ggtitle("Word Length Distribution") +
  theme(plot.title = element_text(hjust = 0.5),
        panel.grid.minor = element_blank())+
  scale_fill_viridis(option="magma" , begin = 0.1, end = 0.8, direction = -1)



```
```{r}
#top word length 
bob_word_lengths %>%
  count(word_length, sort = TRUE) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() + 
  geom_col(aes(word, n), fill = viridis(11, alpha = 0.8)) +
  theme(legend.position = "none", 
        plot.title = element_text(hjust = 0.5),
        panel.grid.major = element_blank()) +
  xlab("") + 
  ylab("Song Count") +
  ggtitle("Most Frequently Used Words in Bob Dylan Lyrics by Word Length") +
  coord_flip()
```

```{r}
wc <- bob_word_lengths %>%
  ungroup() %>%
  select(word, word_length) %>%
  distinct() %>%
  arrange(desc(word_length))

```

```{r}
wordcloud2(wc[1:300, ], 
           size = .15,
           #minSize = .0005,
           #ellipticity = .3, 
           #rotateRatio = 1, 
           fontWeight = "bold",
           )
```


```{r}
#LEXICAL DENSITY AND DIVERSITY
lex_diversity_per_year <- bob %>%
  filter(decade != "NA") %>%
  unnest_tokens(word, lyric) %>%
  group_by(track_title,year) %>%
  summarise(lex_diversity = n_distinct(word)) %>%
  arrange(desc(lex_diversity)) 

diversity_plot <- lex_diversity_per_year %>%
  ggplot(aes(year, lex_diversity)) +
  geom_point(color = "#660033",
             alpha = .4, 
             size = 4, 
             position = "jitter") + 
  stat_smooth(color = "black", se = FALSE, method = "lm") +
  geom_smooth(aes(x = year, y = lex_diversity), se = FALSE,
              color = "#008000", lwd = 2) +
  ggtitle("Lexical Diversity") +
  xlab("") + 
  ylab("") +
  scale_color_manual(values = my_colors) +
  theme_classic() + 
  theme_lyrics()

# Over the last decades there was a clear decrease in Dylan's lyric diversity 

# Lexical density defined as the number of unique words divided by the total number of words which indicates the evtual term repetition acros songs in this case stop words are included 
lex_density_per_year <- bob %>%
  filter(decade != "NA") %>%
  unnest_tokens(word, lyric) %>%
  group_by(track_title,year) %>%
  summarise(lex_density = n_distinct(word)/n()) %>%
  arrange(desc(lex_density))

density_plot <- lex_density_per_year %>%
  ggplot(aes(year, lex_density)) + 
  geom_point(color = "#009999",
             alpha = .4, 
             size = 4, 
             position = "jitter") + 
  stat_smooth(color = "black", 
              se = FALSE, 
              method = "lm") +
  geom_smooth(aes(x = year, y = lex_density), 
              se = FALSE,
              color = "#99004C", 
              lwd = 2) +
  ggtitle("Lexical Density") + 
  xlab("") + 
  ylab("") +
  scale_color_manual(values = my_colors) +
  theme_classic() + 
  theme_lyrics()


grid.arrange(diversity_plot, density_plot, ncol=2)
```

```{r}
popular_tfidf_words <- bob %>%
  unnest_tokens(word, lyric) %>%
  distinct() %>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  count(decade, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, decade, n)

head(popular_tfidf_words)
```

```{r}

top_popular_tfidf_words <- popular_tfidf_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(decade) %>% 
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(decade, tf_idf) %>%
  mutate(row = row_number())

top_popular_tfidf_words %>%
  ggplot(aes(x = row, tf_idf, fill = decade)) +
  geom_col(show.legend = NULL) +
  labs(x = NULL, y = "TF-IDF") + 
  ggtitle("Important Words using TF-IDF by Decade") +
  theme_lyrics() +  
  facet_wrap(~decade, ncol = 6, scales = "free") +
  scale_x_continuous(  # This handles replacement of row 
    breaks = top_popular_tfidf_words$row, # notice need to reuse data frame
    labels = top_popular_tfidf_words$word) +
  coord_flip() 
```


```{r}
tfidf_words_decade <- bob %>%
  unnest_tokens(word, lyric) %>%
  distinct() %>%
  filter(nchar(word) > 3) %>%
  count(decade, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, decade, n) %>%
  arrange(desc(tf_idf))
head(tfidf_words_decade)
```


```{r}
wc <- tfidf_words_decade %>%
  arrange(desc(tf_idf)) %>%
  select(word, tf_idf)


```
```{r}
wordcloud2(wc[1:300, ], 
           size = .15,
           minSize = .0005,
           #ellipticity = .3, 
           #rotateRatio = 1, 
           fontWeight = "bold",
)
```



```{r}
### ZIPFS LAW
# By decade
# Word frequencies 
song_words <- bob %>%
  unnest_tokens(words, lyric) %>%
  count(decade, words, sort = TRUE)
total_words <- song_words %>% 
  group_by(decade) %>%
  summarize(total = sum(n))
song_words <- left_join(song_words, total_words)
song_words
```

```{r}

library(ggplot2)

ggplot(song_words, aes(n/total, fill = decade)) +
  geom_histogram(show.legend = FALSE, bins = 30) +
  #xlim(NA, 0.0009) +
  facet_wrap(~decade, ncol = 6, scales = "free")+
  ggtitle("Term Frequency DIstribution in Bob Dylan Decades")

```
```{r}
#Zipfâ€™s law states that the frequency that a word appears is inversely proportional to its rank.
freq_by_rank <- song_words %>%
  group_by(decade) %>%
  mutate(rank=row_number(), "term frequency"= n/total)
freq_by_rank
# rank column: rank of each word within the frequency table 
```

```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = decade)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Zipf's law by Decade")
# decades similar to each other 
```

```{r}
#By album
song_words <- bob %>%
  unnest_tokens(words, lyric) %>%
  count(album, words, sort = TRUE)
total_words <- song_words %>% 
  group_by(album) %>%
  summarize(total = sum(n))
song_words <- left_join(song_words, total_words)
song_words
```

```{r}
ggplot(song_words, aes(n/total, fill = album)) +
  geom_histogram(show.legend = FALSE, bin = 30, alpha = 0.6) +
  #xlim(NA, 0.0009) +
  facet_wrap(~album, ncol = 4, scales = "free")
```

```{r}
# zipf's law

freq_by_rank <- song_words %>%
  group_by(album) %>%
  mutate(rank=row_number(), "term frequency"= n/total)
freq_by_rank
```
```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = album)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Zipf's law by Album")

```
SENTIMENT ANALYSIS 



```{r}
#Customize the text tables for consistency using HTML formatting
my_kable_styling <- function(dat, caption) {
  kable(dat, "html", escape = FALSE, caption = caption) %>%
    kable_styling(bootstrap_options = c("striped", "condensed", "bordered"),
                  full_width = FALSE)
}

undesirable_words <- c("huh", "lyrics",  "bridge", "fe0f", "yeah", "baby", 
                       "alright", "wanna", "gonna",
                       "whoa", "gotta", "make", "pum",
                       "ooh", "uurh", "pheromone", "poompoom",  
                       "matic", " ai ", " ca ", " la ", "hey", " na ", 
                       " da ", " uh ", " tin ", "  ll", "ooh", "uurh", 
                       "repeats", "la", "da", "uh", "ah")

#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
bob_tidy <- bob %>%
  unnest_tokens(word, lyric) %>% #Break the lyrics into individual words
  filter(!word %in% undesirable_words) %>% #Remove undesirables
  filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
  anti_join(stop_words) #Data provided by the tidytext package


glimpse(bob_tidy)

```

```{r}
## SONG COUNT PER YEAR 
songs_year <- bob %>%
  select(track_title, year) %>%
  group_by(year) %>%
  summarise(song_count = n())

id <- seq_len(nrow(songs_year))
songs_year <- cbind(songs_year, id)
label_data = songs_year
number_of_bar = nrow(label_data) #Calculate the ANGLE of the labels
angle = 90 - 360 * (label_data$id - 0.5) / number_of_bar #Center things
label_data$hjust <- ifelse(angle < -90, 1, 0) #Align label
label_data$angle <- ifelse(angle < -90, angle + 180, angle) #Flip angle
ggplot(songs_year, aes(x = as.factor(id), y = song_count)) +
  geom_bar(stat = "identity", fill = alpha("purple", 0.7)) +
  geom_text(data = label_data, aes(x = id, y = song_count + 10, label = year, hjust = hjust), color = "black", alpha = 0.6, 
            size = 3, angle =  label_data$angle, inherit.aes = FALSE ) +
  coord_polar(start = 0) +
  ylim(-20, 150) + #Size of the circle
  theme_minimal() +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.margin = unit(rep(-4,4), "in"),
        plot.title = element_text(margin = margin(t = 10, b = -10)))


```


```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

